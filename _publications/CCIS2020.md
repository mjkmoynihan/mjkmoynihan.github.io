---
title: "A Self-regulating Spatio-Temporal Filter for Volumetric Video Point Clouds"
collection: publications
permalink: /publication/CCIS2020
excerpt: 'The following work presents a self-regulating filter that is capable of performing accurate upsampling of dynamic point cloud data sequences captured using wide-baseline multi-view camera setups. This is achieved by using two-way temporal projection of edge-aware upsampled point clouds while imposing coherence and noise filtering via a windowed, self-regulating noise filter. We use a state of the art Spatio-Temporal Edge-Aware scene flow estimation to accurately model the motion of points across a sequence and then, leveraging the spatio-temporal inconsistency of unstructured noise, we perform a weighted Hausdorff distance-based noise filter over a given window. Our results demonstrate that this approach produces temporally coherent, upsampled point clouds while mitigating both additive and unstructured noise. In addition to filtering noise, the algorithm is able to greatly reduce intermittent loss of pertinent geometry. The system performs well in dynamic real world scenarios with both stationary and non-stationary cameras as well as synthetically rendered environments for baseline study.'
date: 2020-02-01
venue: ' Communications in Computer and Information Science book series (CCIS, volume 1182)'
paperurl: 'mjkmoynihan.github.io/files/ccis2020.pdf'
citation: 'Moynihan, Matt. (2020). &quot;A Self-regulating Spatio-Temporal Filter for Volumetric Video Point Clouds.&quot; <i>Journal 1</i>. 1(3).'
---

[Download paper here](mjkmoynihan.github.io/files/ccis2020.pdf)
